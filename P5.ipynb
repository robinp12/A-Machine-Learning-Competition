{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A5 - A Machine Learning Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'X_test' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# CHANGER L'INPUT #\n",
    "train_df = read_csv(\"ML-A5-2022_train.csv\", index_col=0)\n",
    "test_df = read_csv(\"ML-A5-2022_test.csv\", index_col=0)\n",
    "\n",
    "# Prendre toutes les columns de données (1000 row x 34979 col)\n",
    "X_train = train_df.iloc[:,:-1]\n",
    "X_test = test_df\n",
    "\n",
    "# Prendre derniere column label (1 cellule tumeur) ou (-1 cellule en santé)\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Prendre les index du testset\n",
    "labels = X_test.index.to_list()\n",
    "\n",
    "%store X_train\n",
    "%store y_train\n",
    "%store X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_df\n",
    "%store -r X\n",
    "%store -r y\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train.head())\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train' (ndarray)\n",
      "Stored 'X_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "%store -r X_train\n",
    "%store -r X_test\n",
    "\n",
    "#Remplacer les NaN par la mediane\n",
    "X_train.fillna(X_train.median(numeric_only=True), inplace=True)\n",
    "X_test.fillna(X_test.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Remplacer les valeurs texte par des int\n",
    "transformer = OrdinalEncoder()\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "\n",
    "transformer_test = OrdinalEncoder()\n",
    "X_test = transformer_test.fit_transform(X_test)\n",
    "\n",
    "%store X_train\n",
    "%store X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND BEST PARAMS FOR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "%store -r X_train\n",
    "%store -r y_train\n",
    "\n",
    "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge',  \n",
    "'perceptron'] \n",
    "penalty = ['l1', 'l2', 'elasticnet'] \n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100] \n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
    "eta0 = [1, 10, 100] \n",
    "param_distributions = dict(loss=loss, \n",
    "                            penalty=penalty, \n",
    "                            alpha=alpha, \n",
    "                            learning_rate=learning_rate, \n",
    "                            eta0=eta0) \n",
    "\n",
    "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5) \n",
    "random = RandomizedSearchCV(estimator=sgd, \n",
    "                            param_distributions=param_distributions, \n",
    "                            verbose=1, n_jobs=-1, \n",
    "                            n_iter=10, error_score='raise') \n",
    "\n",
    "\n",
    "random_result = random.fit(X_train, y_train) \n",
    "print('Best Score: ', random_result.best_score_) \n",
    "print('Best Params: ', random_result.best_params_) \n",
    "\n",
    "# Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "# Best Score:  0.6852563793860644\n",
    "# Best Params:  {'penalty': 'elasticnet', 'loss': 'modified_huber', 'learning_rate': 'optimal', 'eta0': 10, 'alpha': 0.0001}\n",
    "\n",
    "# Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
    "# Best Score:  0.696127216694683\n",
    "# Best Params:  {'penalty': 'l1', 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'eta0': 100, 'alpha': 0.001}\n",
    "\n",
    "# Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
    "# Best Score:  0.7007915966259295\n",
    "# Best Params:  {'penalty': 'l2', 'loss': 'log', 'learning_rate': 'optimal', 'eta0': 1, 'alpha': 100}\n",
    "\n",
    "# Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "# Best Score:  0.73\n",
    "# Best Params:  {'penalty': 'l2', 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'eta0': 1, 'alpha': 0.001} BEST\n",
    "\n",
    "# Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "# Best Score:  0.72\n",
    "# Best Params:  {'penalty': 'l2', 'loss': 'perceptron', 'learning_rate': 'adaptive', 'eta0': 100, 'alpha': 0.01}\n",
    "\n",
    "# Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "# Best Score:  0.731\n",
    "# Best Params:  {'penalty': 'l1', 'loss': 'squared_hinge', 'learning_rate': 'constant', 'eta0': 10, 'alpha': 0.001}\n",
    "\n",
    "# Fitting 5 folds for each of 480 candidates, totalling 2400 fits\n",
    "# Best Score:  0.728\n",
    "# Best Params:  {'alpha': 0.01, 'eta0': 100, 'learning_rate': 'constant', 'loss': 'hinge', 'penalty': 'l2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINIR LE MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "103\n",
      "397\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "\n",
    "model = SGDClassifier(loss=\"modified_huber\", penalty=\"l2\", max_iter=100,learning_rate='invscaling',eta0=1,alpha=0.001, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print((y_pred==1).sum())\n",
    "print((y_pred==-1).sum())\n",
    "df = pd.DataFrame({'':labels, 'Prediction':y_pred})\n",
    "df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFOLD BCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Nested K-Fold Cross-Validation Scores ===\n",
      "Mean balanced accuracy: 0.64\n",
      "Mean balanced accuracy train: 1.0\n",
      "Std balanced accuracy: 0.03\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "import numpy as np\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True,\n",
    "                        random_state=0)\n",
    "\n",
    "acc = []\n",
    "sco = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    print(f\"{i}/5 split\", end='\\r')\n",
    "    model = SGDClassifier(loss=\"modified_huber\", penalty=\"l2\", max_iter=100,learning_rate='invscaling',eta0=1,alpha=0.001, random_state=0)\n",
    "\n",
    "    X_traink, X_testk = X_train[train_index, :], X_train[test_index, :]\n",
    "    y_traink, y_testk = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    model.fit(X_traink, y_traink)\n",
    "    predtrain = model.predict(X_traink)\n",
    "    pred = model.predict(X_testk)\n",
    "    sco.append(balanced_accuracy_score(y_traink, predtrain))\n",
    "    ac = balanced_accuracy_score(y_testk, pred)\n",
    "    acc.append(ac)\n",
    "\n",
    "\n",
    "print(\"=== Nested K-Fold Cross-Validation Scores ===\")\n",
    "print(\"Mean balanced accuracy: \"+ str(round(np.mean(acc), 2)))\n",
    "print(\"Mean balanced accuracy train: \"+ str(round(np.mean(sco), 2)))\n",
    "print(\"Std balanced accuracy: \"+ str(round(np.std(acc), 2)))\n",
    "print('=============================================')\n",
    "\n",
    "# Mean balanced accuracy: 0.64 BEST\n",
    "# Std balanced accuracy: 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# LOAD INTERESTING DATAS\n",
    "train_df = read_csv(\"ML-A5-2022_train.csv\", index_col=0)\n",
    "test_df = read_csv(\"ML-A5-2022_test.csv\", index_col=0)\n",
    "\n",
    "# Prendre toutes les columns de données (1000 row x 34979 col)\n",
    "X_train = train_df.iloc[:,:-1]\n",
    "X_test = test_df\n",
    "\n",
    "# Prendre derniere column label (1 cellule tumeur) ou (-1 cellule en santé)\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Prendre les index du testset\n",
    "labels = X_test.index.to_list()\n",
    "\n",
    "# PREPROCESS\n",
    "\n",
    "#Remplacer les NaN par la mediane\n",
    "X_train.fillna(X_train.median(numeric_only=True), inplace=True)\n",
    "X_test.fillna(X_test.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Remplacer les valeurs texte par des int\n",
    "transformer = OrdinalEncoder()\n",
    "X_train = transformer.fit_transform(X_train)\n",
    "\n",
    "transformer_test = OrdinalEncoder()\n",
    "X_test = transformer_test.fit_transform(X_test)\n",
    "\n",
    "# FIND HYPERPARAMETERS\n",
    "def get_param():\n",
    "    loss = ['hinge', 'log', 'modified_huber', 'squared_hinge',  \n",
    "    'perceptron'] \n",
    "    penalty = ['l1', 'l2', 'elasticnet'] \n",
    "    alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100] \n",
    "    learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
    "    eta0 = [1, 10, 100] \n",
    "    param_distributions = dict(loss=loss, \n",
    "                                penalty=penalty, \n",
    "                                alpha=alpha, \n",
    "                                learning_rate=learning_rate, \n",
    "                                eta0=eta0) \n",
    "\n",
    "    sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5) \n",
    "    random = RandomizedSearchCV(estimator=sgd, \n",
    "                                param_distributions=param_distributions, \n",
    "                                verbose=1, n_jobs=-1, \n",
    "                                n_iter=10, error_score='raise') \n",
    "\n",
    "\n",
    "    random_result = random.fit(X_train, y_train) \n",
    "    print('Best Score: ', random_result.best_score_) \n",
    "    print('Best Params: ', random_result.best_params_) \n",
    "\n",
    "# PREDICT TESTSET\n",
    "\n",
    "model = SGDClassifier(loss=\"modified_huber\", penalty=\"l2\", max_iter=100,learning_rate='invscaling',eta0=1,alpha=0.001, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print((y_pred==1).sum())\n",
    "print((y_pred==-1).sum())\n",
    "\n",
    "df = pd.DataFrame({'':labels, 'Prediction':y_pred})\n",
    "df.to_csv('prediction.csv', index=False)\n",
    "\n",
    "\n",
    "# PERFORM BCR\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True,\n",
    "                        random_state=0)\n",
    "\n",
    "acc = []\n",
    "sco = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    print(f\"{i}/5 split\", end='\\r')\n",
    "    model = SGDClassifier(loss=\"modified_huber\", penalty=\"l2\", max_iter=100,learning_rate='invscaling',eta0=1,alpha=0.001, random_state=0)\n",
    "\n",
    "    X_traink, X_testk = X_train[train_index, :], X_train[test_index, :]\n",
    "    y_traink, y_testk = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    model.fit(X_traink, y_traink)\n",
    "\n",
    "    predtrain = model.predict(X_traink)\n",
    "    pred = model.predict(X_testk)\n",
    "\n",
    "    sco.append(balanced_accuracy_score(y_traink, predtrain))\n",
    "    ac = balanced_accuracy_score(y_testk, pred)\n",
    "\n",
    "    acc.append(ac)\n",
    "\n",
    "print((pred==1).sum())\n",
    "print((pred==-1).sum())\n",
    "print(\"Mean balanced accuracy: \"+ str(round(np.mean(acc), 2)))\n",
    "print(\"Mean balanced accuracy train: \"+ str(round(np.mean(sco), 2)))\n",
    "print(\"Std balanced accuracy: \"+ str(round(np.std(acc), 2)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "673717b79481ea160db82a71a0d386089de33d444566172e83602d3e9189d2a4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
